{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>191024 Microcoleus Isolates Whole Genome Sequence Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declare -a prefix=(\"01\" \"02\" \"03\" \"04\" \"05\" \"06\" \"07\" \"08\" \"09\" \"10\" \"11\")\n",
    "declare -a sample=(\"S5\" \"S6\" \"S7\" \"S8\" \"S9\" \"S10\" \"S11\" \"S12\" \"S13\" \"S14\" \"S15\")\n",
    "\n",
    "for i in {0..10};\n",
    "do\n",
    "    # Identify the correct values\n",
    "    p=${prefix[ $i ]}\n",
    "    s=${sample[ $i ]}\n",
    "\n",
    "module load BBMap/37.93-gimkl-2017a\n",
    "##1a.2. Quality trim reads\n",
    "\n",
    "mkdir 1.bbduk\n",
    "\n",
    "bbduk.sh in1=0.raw/H7M5HBCX3-5203-${p}-00-01_${s}_L002_R1_001.fastq.gz in2=0.raw/H7M5HBCX3-5203-${p}-00-01_${s}_L002_R2_001.fastq.gz \\\n",
    " out1=clean.${p}.1.fastq out2=clean${p}.2.fastq ref=/opt/nesi/mahuika/BBMap/37.93-gimkl-2017a/resources/adapters.fa \\\n",
    "  overwrite=true hdist=1 ktrim=r ordered minlen=80 minlenfraction=0.33 mink=11 tbo tpe rcomp=f k=23 ow=t \n",
    "\n",
    "sleep 5\n",
    "bbduk.sh qtrim=rl trimq=30 minlen=80 in1=clean.${p}.1.fastq in2=clean${p}.2.fastq out1=t.${p}.1.fastq out2=t.${p}.2.fastq outs=t.single.trim.${p}.fastq overwrite=true;done\n",
    "\n",
    "mv clean* t.* 1.bbduk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd 1.bbduk;\n",
    "mkdir fastqc\n",
    "\n",
    "for i in clean*.fastq; do fastqc $i -o fastqc-files -f fastq -t 2; done\n",
    "for i in t.*.fastq; do fastqc $i -o fastqc-files -f fastq -t 2; done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. assembly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load SPAdes/3.13.1-gimkl-2018b\n",
    "\n",
    "mkdir 2-metaspades\n",
    "\n",
    "cd 1.bbduk\n",
    "\n",
    "export FILES=($(ls t*.1.fastq))\n",
    "\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/\\(.*\\).[1/2].fastq/\\1/g')\n",
    "\n",
    "srun metaspades.py -m 100 -t 32 -k 41,61,81,101,127 --pe1-1 $NAME.1.fastq --pe1-2 $NAME.2.fastq --pe1-s $NAME.single.fastq -o ../2-metaspades/st.$NAME.k41-k127\n",
    "\n",
    "\n",
    "for i in {0..11};do mv slurm.2.spades.$i.out slurm.2.spades_$i.out;done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. spade stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir 2-stats-metaspades\n",
    "\n",
    "\n",
    "export FILE=m2000\n",
    "export FILE2=scaffolds\n",
    "export FILE3=contigs\n",
    "\n",
    "for i in {01..11}; do \n",
    "#ruby ~/scripts/extract_contigs_by_length_greater.rb s.t.$i.k41-k127/${FILE3}.fasta 2000 > 2-stats-metaspades/$i.Filter.${FILE}.fa;\n",
    "#ruby ~/scripts/fasta_contig_len_distribution.rb $i.Filter.${FILE}.fasta > 2-stats-metaspades/stats.$i.Filter.${FILE}.fa.txt;\n",
    "##Contig >2kb extract (st):\n",
    "ruby ~/scripts/extract_contigs_by_length_greater.rb 2-metaspades/s.t.$i.k41-k127/${FILE2}.fasta 2000 > 2-stats-metaspades/$i.Filter.${FILE}.fa;\n",
    "##Contig stats (st):\n",
    "ruby ~/scripts/fasta_contig_len_distribution.rb 2-stats-metaspades/$i.Filter.${FILE}.fa > 2-stats-metaspades/stats.$i.Filter.${FILE}.fa.txt;\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. insert size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep 'Insert size' slurm.2.spades* >3-metaspades/insert_size.txt\n",
    "\n",
    "mkdir 5-insert-size\n",
    "mkdir 5-insert-size/bowtie_contigs_meta\n",
    "\n",
    "cd 2-trimseqs; \n",
    "export FILES=($(ls t*.1.fastq))\n",
    "\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/t.\\(.*\\).[1/2].fastq/\\1/g')\n",
    "\n",
    "\n",
    "sleep 5 \n",
    "\n",
    "module load Bowtie/1.2.0-gimkl-2017a #module load Bowtie/1.1.2-intel-2015a\n",
    "cd ../\n",
    "srun bowtie-build -f 5-stats-metaspades/contigs.$NAME.k41-k127.fa 5-insert-size/bowtie_contigs_meta/bowtie_index_contigs$NAME\n",
    "\n",
    "sleep 5\n",
    "\n",
    "\n",
    "srun bowtie --phred33-quals -t -p 5 -n 1 -l 222 --minins 200 --maxins 800 --best \\\n",
    "--sam 5-insert-size/bowtie_contigs_meta/bowtie_index_contigs$NAME \\\n",
    "-1 2-trimseqs/t.$NAME.1.fastq -2 2-trimseqs/t.$NAME.2.fastq > 5-insert-size/bowtie_contigs/$NAME.sam \\\n",
    "2> 5-insert-size/bowtie_contigs/$NAME.log\n",
    "\n",
    "sleep 5\n",
    "\n",
    "grep -v '*' 5-insert-size/bowtie_contigs_meta/$NAME.sam > 5-insert-size/bowtie_contigs_meta/mapped.$NAME.sam\n",
    "\n",
    "sleep 5\n",
    "\n",
    "rm 5-insert-size/bowtie_contigs_meta/$NAME.sam\n",
    "\n",
    "cd 5-insert-size/bowtie_contigs_meta\n",
    "\n",
    "sleep 5\n",
    "\n",
    "srun ruby ~/scripts/mapped_read_stats.rb mapped.$NAME.sam contigs.$NAME.k41-k127.fa --none\n",
    "\n",
    "sleep 5\n",
    "\n",
    "srun grep -E '^:|@' rb_mapping_stats_contigs.$NAME.k41-k127.fa.txt > mapped_coverage_contigs.$NAME.k41-k127.txt\n",
    "\n",
    "srun ruby ~/scripts/fasta_contig_length-gc.rb ../../5-stats-metaspades/contigs.$NAME.k41-k127.fa > gc.contigs.$NAME.k41-k127.fa.txt\n",
    "cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Get ORFs and predicted protein sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load prodigal/2.6.3-GCCcore-7.4.0\n",
    "\n",
    "export FILES=($(ls -1 2-stats-metaspades/{01..11}.Filter.m2000.fa)) \n",
    "\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/\\(.*\\).Filter.m2000.fa/\\1/g')\n",
    "\n",
    "srun prodigal -i 2-stats-metaspades/$NAME.Filter.m2000.fa -o $NAME.genes -a $NAME.genes.faa -d $NAME.genes.fna -m -p met\n",
    "\n",
    "mkdir 5.prodigal_meta\n",
    "\n",
    "mv $NAME* 5.prodigal_meta/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 GC COVERAGE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in *genes.faa;do ruby ~/scripts/fasta_contig_length-gc.rb $i > gc.$i.txt; done\n",
    "for i in gc.*;do sed -i 's/_cov_\\([0-9]\\.[0-9]*\\)_.*_.*_.*_/_cov\\t\\1\\t/g; s/cont=//g; s/Length.*//g' $i;done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Count read length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat Filt.S1_L1_R1.fastq | awk '{if(NR%4==2) print length($1)}' | sort -n | uniq -c > read_length.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. EMIRGE (reconstruct full length ribosomal genes and abundance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. EMIRGE directory:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mkdir 3-emirge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. EMIRGE database and run: (more cpu less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load SAMtools/0.1.19-gimkl-2017a\n",
    "module load Python/2.7.14-gimkl-2017a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load SAMtools/0.1.19-gimkl-2017a\n",
    "module load Python/2.7.14-gimkl-2017a\n",
    "\n",
    "#emirge sbatch (more cores less memory)\n",
    "mkdir 3-emirge/M1; srun emirge.py 3-emirge/M1/ -1 1.bbduk/t.01.1.fastq -2 1.bbduk/t.01.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 502 -s 169 -n 80 -a 32 --phred33 &>3-emirge/M1.log\n",
    "mkdir 3-emirge/M2; srun emirge.py 3-emirge/M2/ -1 1.bbduk/t.02.1.fastq -2 1.bbduk/t.02.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 514 -s 185 -n 80 -a 32 --phred33 &>3-emirge/M2.log\n",
    "# mkdir 3-emirge/M3; srun emirge.py 3-emirge/M3/ -1 1.bbduk/t.03.1.fastq -2 1.bbduk/t.03.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 478 -s 127 -n 80 -a 32 --phred33 &>3-emirge/M3.log\n",
    " mkdir 3-emirge/M4; srun emirge.py 3-emirge/M4/ -1 1.bbduk/t.04.1.fastq -2 1.bbduk/t.04.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 439 -s 165 -n 80 -a 32 --phred33 &>3-emirge/M4.log\n",
    " mkdir 3-emirge/M5; srun emirge.py 3-emirge/M5/ -1 1.bbduk/t.05.1.fastq -2 1.bbduk/t.05.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 434 -s 163 -n 80 -a 32 --phred33 &>3-emirge/M5.log\n",
    " mkdir 3-emirge/M6; srun emirge.py 3-emirge/M6/ -1 1.bbduk/t.06.1.fastq -2 1.bbduk/t.06.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 431 -s 166 -n 80 -a 32 --phred33 &>3-emirge/M6.log\n",
    " mkdir 3-emirge/M7; srun emirge.py 3-emirge/M7/ -1 1.bbduk/t.07.1.fastq -2 1.bbduk/t.07.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 392 -s 155 -n 80 -a 32 --phred33 &>3-emirge/M7.log\n",
    " mkdir 3-emirge/M8; srun emirge.py 3-emirge/M8/ -1 1.bbduk/t.08.1.fastq -2 1.bbduk/t.08.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 501 -s 171 -n 80 -a 32 --phred33 &>3-emirge/M8.log\n",
    " #mkdir 3-emirge/M9; srun emirge.py 3-emirge/M9/ -1 1.bbduk/t.09.1.fastq -2 1.bbduk/t.09.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 478 -s 127 -n 80 -a 32 --phred33 &>3-emirge/M9.log\n",
    " mkdir 3-emirge/M10; srun emirge.py 3-emirge/M10/ -1 1.bbduk/t.10.1.fastq -2 1.bbduk/t.10.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 432 -s 139 -n 80 -a 32 --phred33 &>3-emirge/M10.log\n",
    " mkdir 3-emirge/M11; srun emirge.py 3-emirge/M11/ -1 1.bbduk/t.11.1.fastq -2 1.bbduk/t.11.2.fastq \\\n",
    " -f ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed.fasta \\\n",
    " -b ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.fixed \\\n",
    " -l 251 -i 421 -s 144 -n 80 -a 32 --phred33 &>3-emirge/M11.log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1 Multiple sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {01..11};do sed 's/S1/$i/g' 6a.emirgeS1.sbatch >6a.emirge$i.sbatch;done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 3*sbatch;do sbatch $i;done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Rename: (sbatch) 6b.emirge.rename.sbatch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "export FILES=($(ls -1 3-emirge/M.*.log)) \n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "export DIR=$(echo ${FILENAME} | sed -e 's/\\(3-emirge\\)\\/.*/\\1/g')\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/3-emirge\\/\\(.*\\).log/\\1/g')\n",
    "\n",
    "module load SAMtools/1.3.1-gimkl-2017a\n",
    "module load Python/2.7.14-gimkl-2017a\n",
    "emirge_rename_fasta.py ${DIR}/${NAME}/iter.80 > ${DIR}/${NAME}.i80.fasta\n",
    "\n",
    "#Run array:\n",
    "export FILES=($(ls -1 3-emirge/emirge.*.log)) && NUM=${#FILES[@]} && ZNUM=$(($NUM - 1))\n",
    "if [ $ZNUM -ge 0 ]; then\n",
    "sbatch --array=0-$ZNUM 6b.emirge.rename.sbatch\n",
    "fi\n",
    "\n",
    "or \n",
    "for i in PH2015_*;do emirge_rename_fasta.py $i/iter.80 >$i.i80.fasta;done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Get number of sequences reconstructed per sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 3-emirge/*.i80.fasta; do echo \"#$i\"; grep '>' \"$i\" | wc -l; done\n",
    "\n",
    "#3-emirge/M10.i80.fasta\n",
    "5\n",
    "#3-emirge/M11.i80.fasta\n",
    "7\n",
    "#3-emirge/M1.i80.fasta\n",
    "7\n",
    "#3-emirge/M2.i80.fasta\n",
    "5\n",
    "#3-emirge/M3.i80.fasta\n",
    "5\n",
    "#3-emirge/M4.i80.fasta\n",
    "7\n",
    "#3-emirge/M5.i80.fasta\n",
    "5\n",
    "#3-emirge/M6.i80.fasta\n",
    "8\n",
    "#3-emirge/M7.i80.fasta\n",
    "5\n",
    "#3-emirge/M8.i80.fasta\n",
    "5\n",
    "#3-emirge/M9.i80.fasta\n",
    "3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5. EMRIGE: search and annotate (#)use blast not usearch, MAKE SURE TO USE EMIRGE.RENAME.PY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.5.1. Prep databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load BLAST/2.6.0-gimkl-2017a\n",
    "makeblastdb -in SILVA_132_SSURef_Nr99_tax_silva_trunc.fasta -dbtype nucl \\\n",
    "-out ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.blastdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.5.2 Search using blast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load BLAST\n",
    "for i in 3-emirge/*i80.fasta;do blastn -query $i \\\n",
    "-db ~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.ge1200bp.le2000bp.0.97.blastdb \\\n",
    "-num_threads 12 -outfmt 6 -num_alignments 1 -culling_limit 1 -out $i.SSU132.bln6.txt;done\n",
    "\n",
    "cd 3-emirge\n",
    "\n",
    "for i in *.bln6.txt;do NAME=$(echo ${i} | sed -e 's/\\(.*\\).i80.fasta.SSU132.bln6.txt/\\1/g');\\\n",
    "ruby ~/scripts/annot_blast_emirge_cov.rb $i \\\n",
    "~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.fasta ${NAME}.i80.fasta \\\n",
    "-s ${NAME}.log -l 251;done\n",
    "\n",
    "or \n",
    "\n",
    "ruby ~/scripts/annot_blast_emirge_cov.rb emirgetest.SSU132.bln6.txt  \\\n",
    "~/database/Databases/SILVA_emirge/SILVA_132_SSURef_Nr99_tax_silva_trunc.fasta iter.80.cons.fasta \\\n",
    "-s emirge.bbmap.log -l 251;done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.5.3. Combine annotated output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat annot.*.i80.fasta.SSU132.bln6.txt >annot.emirge.ball.i80-SSU132.bln6.txt;cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. EMRIGE OTU-table: Cluster and annotate emirge hierarchically (use own emirge-convert-priors.rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir 4-clust-emirge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. Remove N's #skip this step as M7 has N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cd 3-emirge; for i in *fasta; do ruby ~/scripts/extract_seqbyNs.rb \"$i\" 10 > ../4-clust-emirge/nn.\"$i\"; done\n",
    "cd ../4-clust-emirge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Sequentially number fasta headers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nn.*.fasta; do ruby ~/scripts/fasta-add-seq-numbering.rb \"$i\" @; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Rename fasta headers with sample info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r.nn.*.fasta; do a=$(echo \"$i\" | sed 's/r.nn.\\(.*\\).i80.fasta/\\1/g'); echo $a; sed 's/>.*Prior=\\(.*\\) Length=\\(.*\\) NormPrior=\\(.*\\)@\\(.*\\)/>'\"$a\"'.\\4;prior=\\1;length=\\2;normprior=\\3;size=\\3;/g' \"$i\" > r\"$i\"; done\n",
    "for i in rr.nn.*.fasta; do a=$(echo \"$i\" | sed 's/rr.nn.\\(.*\\).i80.fasta/\\1/g'); echo $a; sed 's/>.*Prior=\\(.*\\) Length=\\(.*\\) NormPrior=\\(.*\\)@\\(.*\\)/>'\"$a\"'.\\4;size=\\3;/g' \"$i\" > normprior.emirge.\"$a\".i80.fasta; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4. Fasta with read coverage (cov=norm only to seq length; cov.norm=also norm by number mapped reads across samples - norm_seq_mid = seq_mid.to_f * (avelog.to_f / totmapreads.to_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in normprior.*.fasta; do a=$(echo \"$i\" | sed 's/normprior.emirge.\\(.*\\).i80.fasta/\\1/g'); echo $a;\\\n",
    "ruby ~/szescript/emirge-convert-priors.rb \"$i\" ../3-emirge/\"$a\".log rcov.emirge.\"$a\" log; done\n",
    "\n",
    "cat summary-rcov.emirge*.log > all-summary-emirge.log\n",
    "\n",
    "for i in normprior.*.fasta; do a=$(echo \"$i\" | sed 's/normprior.emirge.\\(.*\\).i80.fasta/\\1/g'); echo $a;\\\n",
    "ruby ~/szescript/emirge-convert-priors.rb \"$i\" ../3-emirge/\"$a\".log \"$a\" 251 all-summary-emirge.log; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5. Concatenate fastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat normprior.emirge.*.fasta > all.normprior.emirge.fasta\n",
    "cat cov.*.fasta > all.cov.emirge.fasta\n",
    "cat cov.norm.*.fasta > all.cov.norm.emirge.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6. Scale normpriors to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruby ~/scripts/emirge-scale-priors.rb all.normprior.emirge.fasta all.scale.normprior.emirge\n",
    "rm all.normprior.emirge.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7. Rename coverage/normprior headers for uclust: 'prior' to 'size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed -i 's/prior=/size=/g; s/\\(>.*\\)/\\1;/g' all.cov*emirge.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.8. Sort by length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all.*.emirge.fasta; do usearch -sortbylength \"$i\" -fastaout sort.\"$i\" -minseqlength 500; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.9. Non-global clustering with UCLUST (partial matches allowed): 97 and 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.drive5.com/usearch/manual/uclust_algo.html\n",
    "for i in sort.all.*.emirge.fasta; do usearch -cluster_fast \"$i\" -id 0.97 -centroids clust.97.\"$i\"; done\n",
    "for i in sort.all.*.emirge.fasta; do usearch -cluster_fast \"$i\" -id 1.00 -centroids clust.100.\"$i\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.10. Generate OTU table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in clust.97.sort.all.*.emirge.fasta; do a=$(echo $i | sed 's/clust.*.sort.\\(.*\\).fasta/\\1/g');\\\n",
    "b=$(echo $i | sed 's/clust.\\(.*\\).sort.*.fasta/\\1/g'); usearch -usearch_global sort.\"$a\".fasta -db \"$i\" \\\n",
    "-strand plus -id 0.97 -otutabout otu-table.\"$b\".\"$a\".txt; done\n",
    "\n",
    "for i in clust.100.sort.all.*.emirge.fasta; do a=$(echo $i | sed 's/clust.*.sort.\\(.*\\).fasta/\\1/g');\\\n",
    "b=$(echo $i | sed 's/clust.\\(.*\\).sort.*.fasta/\\1/g'); usearch -usearch_global sort.\"$a\".fasta -db \"$i\" \\\n",
    "-strand plus -id 1.00 -otutabout otu-table.\"$b\".\"$a\".txt; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.11. Annotate part 1: SINTAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in clust.*.fasta; do usearch -sintax \"$i\" -db /home/htee663/database/Databases/SILVA_132_NR99/silva132_99.utax.udb \\\n",
    "-tabbedout \"$i\".sintax -strand both -sintax_cutoff 0.8 -threads 36; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.12. Annotate part 2: Add taxa to OTU table ****and remove rows summing to <2****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in clust.*.sintax; do NAME=$(echo $i | sed 's/clust.\\(.*\\).sort.\\(.*\\).fasta.sintax/\\1.\\2/g'); \\\n",
    "echo ${NAME}; ruby ~/szescript/annot-sintax-otutable-nopath.rb \"$i\" otu-table.${NAME}.txt 0; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Rarefaction + R plotting to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 bowtie mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir 6a-metaspades-mapped-coverage-binning\n",
    "\n",
    "export FILES=($(ls -1 2-stats-metaspades/scaffold.*.fa))\n",
    "export FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "export DIR1=$(echo ${FILENAME} | sed -e 's/\\(2-stats-metaspades\\)\\/.*/\\1/g')\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/\\(scaffold.*\\).fa/\\1/g')\n",
    "export SAMPLE=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/scaffold.i.\\(b.*\\)\\..*.fa/\\1/g')\n",
    "export DIR2=6a-metaspades-mapped-coverage-binning\n",
    "\n",
    "##Mapping: --mem-per-cpu=2000 --cpus-per-task=5\n",
    "for FILENAME in 2-stats-metaspades/*m2000.fa;do export NAME=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/\\(.*\\).Filter.m2000.fa/\\1/g'); mkdir ${DIR2}/bowtie_${NAME}; bowtie-build -f ${FILENAME} ${DIR2}/bowtie_${NAME}/bowtie_index_contigs;done\n",
    "\n",
    "\n",
    "export DIR1=6a-metaspades-mapped-coverage-binning\n",
    "export DIR2=1.bbduk\n",
    "##Mapping: --mem-per-cpu=2000 --cpus-per-task=5\n",
    "for FILENAME in 6a-metaspades-mapped-coverage-binning/*;do export NAME=$(echo $FILENAME | sed -e 's/6a-metaspades-mapped-coverage-binning\\/bowtie_//g'); \\\n",
    " bowtie --phred33-quals -t -p 5 -n 1 -l 251 --minins 200 --maxins 800 --best --sam ${FILENAME}/bowtie_index_contigs \\\n",
    " -1 ${DIR2}/t.${NAME}.1.fastq -2 ${DIR2}/t.${NAME}.2.fastq> ${DIR1}/${NAME}.sam 2> ${DIR1}/${NAME}.log; done\n",
    "\n",
    "sleep 5\n",
    "\n",
    "for FILENAME in 6a-metaspades-mapped-coverage-binning/*.sam;do export NAME=$(echo $FILENAME | sed -e 's/6a-metaspades-mapped-coverage-binning\\/\\(.*\\).sam//g'); \\\n",
    " grep -v '*' $FILENAME > 6a-metaspades-mapped-coverage-binning/mapped.$NAME.sam;done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping stats\n",
    "export DIR1=6a-metaspades-mapped-coverage-binning\n",
    "export DIR2=1.bbduk\n",
    "export a=($(ls 6a-metaspades-mapped-coverage-binning/|grep 'bowtie_'))\n",
    "\n",
    "FILENAME=${a[$SLURM_ARRAY_TASK_ID]}\n",
    "export NAME=$(echo $FILENAME | sed -e 's/bowtie_//g')\n",
    "\n",
    "cd ${DIR1}/\n",
    "srun ruby ~/scripts/mapped_read_stats.rb mapped.${NAME}.sam ${NAME} --none\n",
    "srun grep -E '^:|@' rb_mapping_stats_${NAME}.txt > mapped.coverage.${NAME}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###9a. Mapped reads\n",
    "export FILES=($(ls -1 6a-metaspades-mapped-coverage-binning/mapped*.sam))\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "\n",
    "export DIR1=6a-metaspades-mapped-coverage-binning\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/6a-metaspades-mapped-coverage-binning\\/\\(mapped.*\\).sam/\\1/g')\n",
    "\n",
    "module load SAMtools/1.3.1-gimkl-2017a\n",
    "srun samtools view -b ${FILENAME} -o ${DIR1}/${NAME}.bam\n",
    "srun samtools sort ${DIR1}/${NAME}.bam -o ${DIR1}/sort.${NAME}.bam -T ${DIR1}/temp.sort.${NAME}.bam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='black'>9.2 Metabat</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metabat\n",
    "mkdir 6b-metaspades-bin-metabat\n",
    "\n",
    "###9b. MetaBAT prep\n",
    "export DIR1=6b-metaspades-bin-metabat\n",
    "export DIR2=6a-metaspades-mapped-coverage-binning\n",
    "export FILES=($(ls -1 2-stats-metaspades/*m2000.fa))\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/\\(.*\\).Filter.m2000.fa/\\1/g')\n",
    "\n",
    "srun /home/htee663/database/Software/metabat_v2.12.1/jgi_summarize_bam_contig_depths --outputDepth ${DIR1}/depth.${NAME}.txt ${DIR2}/sort.mapped.${NAME}.bam\n",
    "\n",
    "\n",
    "###c. MetaBAT bin\n",
    "export DIR1=6b-metaspades-bin-metabat\n",
    "export FILES=($(ls -1 2-stats-metaspades/*.fa))\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/\\(.*\\).Filter.m2000.fa/\\1/g')\n",
    "\n",
    "module load MetaBAT/2.13-GCC-7.4.0\n",
    "\n",
    "\n",
    "#srun metabat2 -t 5 -s 100000 -i ${FILENAME} -a ${DIR1}/depth.${NAME}.txt -o ${DIR1}/metabat1-${NAME}/bin.${NAME} --unbinned ${DIR1}/metabat1-${NAME}/bin.${NAME} #--saveCls ${DIR1}/metabat1-${NAME}/bin.${NAME}\n",
    "for i in 2-stats-metaspades/*.fa;do export NAME=$(echo ${i} | sed -e 's/2-stats-metaspades\\/\\(.*\\).Filter.m2000.fa/\\1/g'); \\\n",
    "mkdir ${DIR1}/metabat2-${NAME};  /home/htee663/database/Software/metabat_v2.12.1/metabat2 -t 20 -s 50000 -i ${i} -a 6b-metaspades-bin-metabat/depth.${NAME}.txt -o 6b-metaspades-bin-metabat/metabat2-${NAME}/bin.${NAME} --unbinned ${DIR1}/metabat2-${NAME}/bin.${NAME};done\n",
    "\n",
    "##Summarize bins into lists: tab delimited (sample\\tbin.*\\tnode)\n",
    "for a in metabat2-*; do cd $a; n=$(echo \"$a\" | sed 's/metabat2-/metabat2./g'); for i in bin.*.fa; do s=$(echo \"$i\" | sed 's/bin.\\(.*\\)\\.\\(.*\\)\\.fa/\\1/g'); b=$(echo $i | sed 's/bin.\\(.*\\)\\.\\(.*\\)\\.fa/\\2/g'); echo \"$s\"; grep '>' $i | sed 's/>/'\"$s\"'\\tbin.'\"$b\"'\\t/g' > list.\"$i\"; done && cat list.* > ../list.$n.bins.txt; cd ../; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Maxbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###9c. Binning - MaxBin: metaspades\n",
    "mkdir 6c-metaspades-bin-maxbin\n",
    "##Prepare coverage files:\n",
    "cp 6a-metaspades-mapped-coverage-binning/mapped.coverage.* 6c-spades-bin-maxbin/\n",
    "cd 6c-metaspades-bin-maxbin/\n",
    "for i in mapped.*.txt; do grep '@' \"$i\" | cut -f2,6 > cov.\"$i\"; done;cd ../\n",
    "##Get complete contig list and assign coverage zero if missing from mapped file\n",
    "for i in 2-stats-metaspades/*.fa; do a=$(echo \"$i\" | sed 's/2-.*\\/\\(.*fa\\)/\\1/g'); echo $a; grep '>' \"$i\" > 6c-metaspades-bin-maxbin/node.list.\"$a\".txt; done\n",
    "for i in 6c-metaspades-bin-maxbin/node.list.*;do sed -i 's/>//g' $i;done\n",
    "cd 6c-metaspades-bin-maxbin/\n",
    "for i in cov.mapped.*.txt; do a=$(echo \"$i\" | sed 's/cov.mapped.coverage.\\([^\\.]*\\).txt/\\1/g'); echo $a; ruby ~/scripts/match.contigs.contigs-coverage.rb node.list.\"$a\".Filter.m2000.fa.txt \"$i\" all.\"$i\"; done\n",
    "##Run MaxBin array - submit from login node: ###Inconsistencies with finding software paths\n",
    "\n",
    "\n",
    "export DIR1=6c-metaspades-bin-maxbin\n",
    "export FILES=($(ls -1 2-stats-metaspades/*.fa))\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "export NAME=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/\\(.*\\).Filter.m2000.fa/\\1/g')\n",
    "\n",
    "srun /home/htee663/database/Software/maxbin_v2.2.4/run_MaxBin.pl -contig ${FILENAME} -abund ${DIR1}/all.cov.mapped.coverage.*.txt -out ${DIR1}/maxbin.scaffolds.${NAME}.txt -thread 2\n",
    "\n",
    "or \n",
    "#for i in  2-stats-metaspades/*.fa;do export NAME=$(echo ${FILENAME} | sed -e 's/2-stats-metaspades\\/\\(.*\\).Filter.m2000.fa/\\1/g');perl /home/htee663/database/Software/maxbin_v2.2.4/run_MaxBin.pl -contig ${i} -abund ${DIR1}/all.cov.mapped.coverage.${NAME}.txt -out ${DIR1}/maxbin.scaffolds.${NAME}.txt -thread 24;done\n",
    "\n",
    "##Summarize bins into lists: tab delimited (sample\\tbin.*\\tnode)\n",
    "cd 6c-metaspades-bin-maxbin\n",
    "for a in maxbin_*; do cd $a; for i in maxbin.*.fasta; do s=$(echo \"$i\" | sed 's/maxbin.scaffolds.\\(.*\\).txt.\\(.*\\).fasta/\\1/g'); b=$(echo \"$i\" | sed 's/maxbin.scaffolds.\\(.*\\).txt.\\(.*\\).fasta/\\2/g'); echo \"$s\"; echo \"$b\"; grep '>' $i | sed 's/>/'\"$s\"'\\tbin.'\"$b\"'\\t/g' > list.\"$i\"; done && cat list.*.fasta > ../list.$a.bins.txt; cd ../; done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 CONCOCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###9d. Binning - CONCOCT: spades\n",
    "mkdir 6d-metaspades-bin-concoct\n",
    "##Prepare coverage files:\n",
    "##9d.1. Cut contigs to equal lengths of 10kb min and <20kb:\n",
    "source activate concoct_env #Run using <concoct> plus parameters #Deactivate using <source deactivate concoct_env>\n",
    "#e.g.:   python $CONCOCT/scripts/cut_up_fasta.py -c 10000 -o 0 -m contigs.fa > frag.10k.contigs.fa\n",
    "for i in 2-stats-metaspades/*.fa; do a=$(echo \"$i\" | sed 's/2-.*\\/\\(.*fa\\)/\\1/g'); echo \"$a\"; cut_up_fasta.py -c 10000 -o 0 -m \"$i\" -b 6d-metaspades-bin-concoct/frag.10k.\"$a\".bed > 6d-metaspades-bin-concoct/frag.10k.\"$a\"; done\n",
    "##9d.2. Create the input table (containing average coverage per sample and contig)\n",
    "##9d.2b. Build index\n",
    "for i in 6a-metaspades-mapped-coverage-binning/sort.mapped*; do samtools index $i;done\n",
    "\n",
    "\n",
    "##9d.2d. Make coverage table:\n",
    "##Make coverage table\n",
    "\n",
    "for i in 6d-metaspades-bin-concoct/frag.10k.*.bed;do a=$(echo \"$i\" | sed 's/6d-.*\\/frag.10k.\\(.*\\).Filter.m2000.fa.bed/\\1/g'); \\\n",
    "concoct_coverage_table.py $i 6a-metaspades-mapped-coverage-binning/sort.mapped.$a.bam >  6d-metaspades-bin-concoct/frag.10k.cov.$a.txt; done\n",
    "\n",
    "# Bin the fragments\n",
    "for i in 6d-metaspades-bin-concoct/frag.10k.cov.*.txt;do a=$(echo \"$i\" | sed 's/6d-.*\\/frag.10k.cov.\\(.*\\).txt/\\1/g');\\\n",
    "concoct --composition_file 6d-metaspades-bin-concoct/frag.10k.$a.Filter.m2000.fa --coverage_file $i -b concoct-output-$a;done\n",
    "\n",
    "# Cluster the fragments back into their original form (python script rm points)\n",
    "#for i in 6d-metaspades-bin-concoct/concoct-output-*; do cd $i; merge_cutup_clustering.py clustering_gt1000.csv > clustering_merged.csv;cd ../../;done\n",
    "for i in 6d-metaspades-bin-concoct/concoct-output-*; do a=$(echo \"$i\" | sed 's/6d-.*\\/concoct-output-\\(.*\\)/\\1/g');\\\n",
    "sed -e 's/\\(NODE_[0-9]*_length_[0-9]*_cov_[0-9]*\\.[0-9]*\\).*,\\([0-9]*\\)/\\1,bin.\\2/g;s/\\(NODE_[0-9]*_length_[0-9]*_cov_[0-9]*\\),\\([0-9]*\\)/\\1,bin.\\2/g;s/bin.\\([1-9][0-9]\\)$/bin.0\\1/g;s/bin.\\([1-9]\\)$/bin.00\\1/g' \\\n",
    "${i}/clustering_gt1000.csv | sort -k1,1 -u > $i/concoct-${a}-das.txt; done\n",
    "\n",
    "# Create the bins\n",
    "for i in 6d-metaspades-bin-concoct/concoct-output-*;do a=$(echo \"$i\" | sed 's/6d-.*\\/concoct-output-\\(.*\\)/\\1/g');\\\n",
    "mkdir $i/fasta_bins/; extract_fasta_bins.py 2-stats-metaspades/$a.Filter.m2000.fa ${i}/concoct-$a-das.txt \\\n",
    "--output_path ${i}/fasta_bins/; done\n",
    "\n",
    "##Deactivate concoct:\n",
    "source deactivate concoct_env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 DasTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source /nesi/project/uoa02469/Software/PipelineSetup/binning.sh\n",
    "source /nesi/project/uoa02469/Software/PipelineSetup/genomic.sh\n",
    "module load BLAST/2.6.0-gimkl-2017a\n",
    "module load R/3.5.1-gimkl-2017a\n",
    "\n",
    "#Installation of dependent R-packages:\n",
    "R\n",
    "repo='http://cran.us.r-project.org' #select a repository\n",
    "install.packages('doMC', repos=repo, dependencies = T)\n",
    "install.packages('data.table', repos=repo, dependencies = T)\n",
    "install.packages('ggplot2', repos=repo, dependencies = T)\n",
    "q() #quit R-session\n",
    "\n",
    "unzip DAS_Tool-1.x.x.zip\n",
    "cd ./DAS_Tool-1.x.x\n",
    "R CMD INSTALL ./package/DASTool_1.x.x.tar.gz\n",
    "\n",
    "#make new dir\n",
    "mkdir 6e.metaspades-bin-dastool;cd 6e.metaspades-bin-dastool\n",
    "# Create a MetaBAT input file\n",
    "for i in ../6b-metaspades-bin-metabat/metabat2-*;do a=$(echo \"$i\" | sed 's/..\\/6b-.*\\/metabat2-\\(.*\\)/\\1/g');\\\n",
    "grep \">\" $i/*[0-9].fa | sed 's/.fa:>/\\t/g' | awk 'OFS=\"\\t\" {print $2,$1}' > metabat.$a.txt;done\n",
    "for i in metabat.*;do sed -i 's/..\\/.*bin.*\\./metabat./g;s/scaff.*.txt.//g' $i;done\n",
    "\n",
    "# Create a MaxBin input file\n",
    "for i in ../6c-metaspades-bin-maxbin/maxbin_*;do a=$(echo \"$i\" | sed 's/..\\/6c-.*\\/maxbin_\\(.*\\)/\\1/g');\\\n",
    "grep \">\" $i/maxbin*fasta | sed 's/.fasta:>/\\t/g' | awk 'OFS=\"\\t\" {print $2,$1}' > maxbin.$a.txt;done\n",
    "for i in maxbin.*;do sed  -i 's/..\\/.*bin/maxbin/g;s/scaff.*.txt.//g' $i;done\n",
    "\n",
    "\n",
    "# Create a CONCOCT input file\n",
    "for i in ../6d-metaspades-bin-concoct/concoct-output-*;do a=$(echo \"$i\" | sed 's/..\\/6d-.*\\/concoct-output-\\(.*\\)/\\1/g');\\\n",
    "grep \">\" $i/fasta_bins/*.fa | sed 's/.fa:>/\\t/g' | awk 'OFS=\"\\t\" {print $2,$1}' > concoct.$a.txt;done\n",
    "for i in concoct.*;do sed -i 's/..\\/.*bin/bin/g' $i;done\n",
    "\n",
    "# Run DAS_Tool\n",
    "for a in {01..11};do mkdir dastool_$a;DAS_Tool -i metabat.$a.txt,maxbin.$a.txt,concoct.$a.txt \\\n",
    "-l metabat,maxbin,concoct -t 36 --write_bins 1 --search_engine blast -c ../2-stats-metaspades/$a.Filter.m2000.fa \\\n",
    "--db_directory /opt/nesi/CS400_centos7_bdw/DAS_Tool/1.1.1-gimkl-2018b-R-3.6.1/ -o dastool_$a/$a;done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6 dRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CheckM:\n",
    "\n",
    "#pip install drep --user\n",
    "    \n",
    "mkdir 6f.metaspades-bin-drep;\n",
    "for i in {01..11}; \\\n",
    "do mkdir 6f.metaspades-bin-drep/checkm_$i; checkm lineage_wf -t 20 --pplacer_threads 20 \\\n",
    "-x fa --tab_table -f bins_drep_checkm_$i 6e.metaspades-bin-dastool/dastool_${i}/${i}_DASTool_bins/ \\\n",
    "6f.metaspades-bin-drep/checkm_$i/ &> 6f.metaspades-bin-drep/checkm.$i.log;done\n",
    "# Reformat the output\n",
    "for i in {01..11}; \\\n",
    "do echo \"genome,completeness,contamination\" > dRep.genomeInfo_$i\n",
    "cut -f1,12 bins_drep_checkm_$i| sed 's/\\t/.fa,/g' > p1$i.txt\n",
    "cut -f13 bins_drep_checkm_$i > p2$i.txt\n",
    "paste -d \",\" p1$i.txt p2$i.txt | tail -n+2 >> dRep.genomeInfo_$i\n",
    "rm p1* p2*\n",
    "\n",
    "# Run dRep\n",
    "dRep dereplicate --genomeInfo dRep.genomeInfo_${i} \\\n",
    "-g 6e.metaspades-bin-dastool/dastool_${i}/${i}_DASTool_bins/* -p 36 6f.metaspades-bin-drep/drep_${i}/; done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count genomes\n",
    "for i in {01..11};do ls 6f.metaspades-bin-drep/drep_${i}/dereplicated_genomes/*fa |wc -l;done\n",
    "for i in {01..11};do ls 6e.metaspades-bin-dastool/dastool_${i}/${i}_DASTool_bins/*fa |wc -l;done\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Drep-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CheckM\n",
    "source ~/login.sh\n",
    "mkdir 6g.metaspades-all-bin-drep;\n",
    "mkdir 7.final_bin\n",
    "module load Mash/2.1-gimkl-2018b\n",
    "\n",
    "for i in {01..11};do for n in  6f.metaspades-bin-drep/drep_${i}/dereplicated_genomes/*; \\\n",
    "do export NAME=$(echo ${n} | sed -e 's/6f.metaspades-bin-drep.*genomes\\/\\(.*\\)/\\1/g'); \\\n",
    "cp ${n} 6g.metaspades-all-bin-drep/S${i}_${NAME};done;done\n",
    "\n",
    " mkdir 6g.metaspades-all-bin-drep/checkm; checkm lineage_wf -t 20 --pplacer_threads 20 \\\n",
    "-x fa --tab_table -f 6g.metaspades-all-bin-drep/bins_drep_checkm 6g.metaspades-all-bin-drep/  6g.metaspades-all-bin-drep/checkm/ &> 6g.metaspades-all-bin-drep/checkm.log\n",
    "\n",
    "\n",
    "# Reformat the output\n",
    "echo \"genome,completeness,contamination\" > 6g.metaspades-all-bin-drep/dRep.genomeInfo\n",
    "cut -f1,12 6g.metaspades-all-bin-drep/bins_drep_checkm| sed 's/\\t/.fa,/g' > p1.txt\n",
    "cut -f13 6g.metaspades-all-bin-drep/bins_drep_checkm > p2.txt\n",
    "paste -d \",\" p1.txt p2.txt | tail -n+2 >> 6g.metaspades-all-bin-drep/dRep.genomeInfo\n",
    "rm p1* p2*\n",
    "\n",
    "# Run dRep\n",
    "ml MUMmer/3.23-gimkl-2017a\n",
    " module load Python/3.7.3-gimkl-2018b\n",
    "dRep dereplicate --genomeInfo 6g.metaspades-all-bin-drep/dRep.genomeInfo -g 6g.metaspades-all-bin-drep/*.fa -p 24  7.new.final_bin/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Bin coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 5. Pairwise mapping - Bin coverage calculation for differential genome coverage table\n",
    "mkdir 7b-Refined-bins\n",
    "### 1. Separate refined derep bins back to original sample\n",
    "cd 7b-Refined-bins\n",
    "mkdir all-refined-derep-bins-divided-per-sample\n",
    "for i in {01..11}; do mkdir all-refined-derep-bins-divided-per-sample/S\"$i\" && cp ../7.final_bin/S\"$i\"*.fa all-refined-derep-bins-divided-per-sample/S\"$i\"/.; done\n",
    "\n",
    "\n",
    "# Create list of binned scaffolds for each sample\n",
    "for SAMPLE in {01..11};do \n",
    "cd /home/htee663/nobackup446/practice/practice/4.191024_comparative_Microcoleus/7b-Refined-bins/all-refined-derep-bins-divided-per-sample/S${SAMPLE}\n",
    "for f in *.fa; do grep \">\" ${f} > ${f}.txt; done\n",
    "for f in *.txt; do sed -i \"s/$/\\t$f/\" $f; done\n",
    "cat *.txt > ${SAMPLE}.scaffolds2bin.txt && rm *.fa.txt\n",
    "sed -i 's/.txt*//g' ${SAMPLE}.scaffolds2bin.txt | sed -i 's/>*//g' ${SAMPLE}.scaffolds2bin.txt ;done\n",
    "\n",
    "### 2. Pairwise mapping with Bowtie (using indecies of assemblies already created step 5)\n",
    "cd ../../../\n",
    "mkdir 8-mapping-pairwise\n",
    "for i in {01..11}; do mkdir 8-mapping-pairwise/S\"$i\"; done\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH -A uoa00446\n",
    "#SBATCH -J 8.bin.cov.map.array\n",
    "#SBATCH --time 36:00:00\n",
    "#SBATCH --mem 5GB\n",
    "#SBATCH --array=01-11\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task 30\n",
    "#SBATCH -e slurm-8.bin.cov.map.array.%A-%a.err\n",
    "#SBATCH -o slurm-8.bin.cov.map.array.%A-%a.out\n",
    "\n",
    "module load Bowtie/1.2.0-gimkl-2017a\n",
    "\n",
    "declare -a array=(echo {01..11})\n",
    "\n",
    "for i in {01..11};\n",
    "do\n",
    "\n",
    "srun bowtie-build -f 2-stats-metaspades/${i}.Filter.m2000.fa 8-mapping-pairwise/bowtie_index/${i}_bowtie_index\n",
    "\n",
    "    srun bowtie --phred33-quals -t -p 30 -n 1 -l 222 --minins 200 --maxins 800 --best --sam 8-mapping-pairwise/bowtie_index/${array[$SLURM_ARRAY_TASK_ID]}_bowtie_index \\\n",
    "        -1 1.bbduk/t.${i}.1.fastq \\\n",
    "        -2 1.bbduk/t.${i}.2.fastq \\\n",
    "        >8-mapping-pairwise/S${array[$SLURM_ARRAY_TASK_ID]}/extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta.sam \\\n",
    "        2> 8-mapping-pairwise/S${array[$SLURM_ARRAY_TASK_ID]}/extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta.log;\n",
    "done\n",
    "\n",
    "## Run as \n",
    "sbatch 8.bin.cov.map.pairwise.sbatch\n",
    "\n",
    "# Mapping stats\n",
    "\n",
    "# In 8.bin.cov.map.stats.sbatch\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH -A uoa00446\n",
    "#SBATCH -J 8.bin.cov.map.stats.array\n",
    "#SBATCH --time 6:00:00\n",
    "#SBATCH --mem 10GB\n",
    "#SBATCH --array=1-11\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task 2\n",
    "#SBATCH -e slurm-8.bin.cov.map.stats.array.%A-%a.err\n",
    "#SBATCH -o slurm-8.bin.cov.map.stats.array.%A-%a.out\n",
    "\n",
    "declare -a array=(echo {01..11})\n",
    "\n",
    "cd /home/htee663/nobackup446/practice/practice/4.191024_comparative_Microcoleus/8-mapping-pairwise/S${array[$SLURM_ARRAY_TASK_ID]}\n",
    "\n",
    "sleep 5\n",
    "\n",
    "for i in {01..11};\n",
    "do \n",
    "    grep -v '*' extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta.sam > map.extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta.sam; \n",
    "done\n",
    "\n",
    "##Get mapped read stats:\n",
    "for i in {01..11}; \n",
    "do \n",
    "    ruby /home/htee663/scripts/mapped_read_stats.rb map.extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta.sam extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta --none; \n",
    "done\n",
    "\n",
    "##Grab coverage information (leaving stats):\n",
    "for i in {01..11}; \n",
    "do\n",
    "    srun grep -E '^:|@' rb_mapping_stats_extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta.txt > mapped_coverage_extract.scaffolds.S${array[$SLURM_ARRAY_TASK_ID]}.vs.S${i}.fasta.txt;\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3. Number of reads per contig per sample\n",
    "#find read length\n",
    "\n",
    "cd 8-mapping-pairwise\n",
    "for n in {01..11};do echo $n >>all.read.length.txt;for i in S${n}/rb_mapping_stats_extract.scaffolds.S${n}.vs.S*;\\ \n",
    "do awk 'NR==5' $i >> all.read.length.txt;done;done\n",
    "\n",
    "\n",
    "for i in {01..11}; do cp S\"$i\"/mapped* . && cat *.vs.S\"$i\".fasta.txt > all.vs.S\"$i\".txt; done\n",
    "for i in {01..11}; do grep '' S\"$i\"/\n",
    "rm mapped*\n",
    "rm -r S* # sam files too big\n",
    "\n",
    "for i in {01..11}; do awk '{print $2 \"\\t\" $4}' all.vs.S\"$i\".txt > all.vs.S\"$i\"-2col.txt; done\n",
    "\n",
    "# Get list of scaffolds in each assembly\n",
    "for i in ../2-stats-metaspades/*m2000.fa;do grep '>' $i | sed 's/>//g' > list.scaffolds.in.all.assemblies.txt; done\n",
    "for i in {01..11}; do grep \">\" ../2-stats-metaspades/\"$i\".Filter.m2000.fa > S\"$i\"-list.scaffolds.in.assembly.txt; done\n",
    "\n",
    "sed -i 's/>*//g' *-list.scaffolds.in.assembly.txt\n",
    "cat *-list.scaffolds.in.assembly.txt > list.scaffolds.in.all.assemblies.txt\n",
    "\n",
    "for SAMPLE in {01..11};do \n",
    "ruby /home/htee663/scripts/match.contigs.contigs-coverage.rb list.scaffolds.in.all.assemblies.txt all.vs.S${SAMPLE}-2col.txt \\\n",
    "all.vs.S${SAMPLE}-node_reads.txt;done\n",
    "\n",
    "\n",
    "\n",
    "### Extract contig length from list of scaffolds\n",
    "cp list.scaffolds.in.all.assemblies.txt list.scaffolds.in.all.assemblies-contig_length.txt\n",
    "sed -i 's/.*_length_\\(.*\\)_cov.*/\\1/g' list.scaffolds.in.all.assemblies-contig_length.txt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make coverage table in R  \n",
    "refer: 10.genome-coverage-table.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. GTDB (Taxonomic classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source /nesi/project/uoa02469/Software/PipelineSetup/gtdbtk.sh\n",
    "gtdbtk classify_wf  --min_perc_aa 50 --cpus 16 --genome_dir 7.final_bin/ --out_dir 9.gtdboutbins/ --extension fa\n",
    "\n",
    "##Combine coverage table and taxonomic classification and completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.  Genome Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Prodigal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source ~/login.sh\n",
    "source /nesi/project/uoa02469/Software/PipelineSetup/gtdbtk.sh\n",
    "\n",
    "#mkdir 11-bin-annotation\n",
    "export FILES=($(ls -1 7.final_bin/S*.fa)) \n",
    "\n",
    "FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "export NAME=$(echo ${FILES} | sed -e 's/7.final_bin\\/\\(S.*\\).fa/\\1/g')\n",
    "\n",
    "srun prodigal -q -p single -i $FILENAME -d 11-bin-annotation/$NAME.prod.fna -a 11-bin-annotation/$NAME.prod.faa -o 11-bin-annotation/$NAME.genes.gff -f gff\n",
    "\n",
    "\n",
    "sed 's/ .*//g' $NAME.prod.faa > $NAME.prod.no_metadata.faa\n",
    "sed 's/ .*//g' $NAME.prod.fna > $NAME.prod.no_metadata.fna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 usearch (uniprot, uniref100,kegg100) + hmmsearch (pfam, tigrfam, dbcan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source /nesi/project/uoa02469/Software/PipelineSetup/annotation.sh\n",
    "\n",
    "cd 11-bin-annotation\n",
    "#export FILES=($(ls -1 *metadata.faa)) \n",
    "\n",
    "#FILENAME=${FILES[$SLURM_ARRAY_TASK_ID]}\n",
    "for FILENAME in *metadata.faa;do export NAME=$(echo ${FILENAME} | sed -e 's/\\(.*\\).prod.no_metadata.faa/\\1/g');\n",
    "\n",
    "usearch -id 0.5 -evalue 0.001 -maxhits 10 -top_hits_only -threads 32\\\n",
    "                           -userfields query+target+tlo+thi+id+bits+evalue \\\n",
    "                           -db $UNIPROT_udb -usearch_global ${NAME}.prod.no_metadata.faa -threads 32 -userout ${NAME}.prod.uniprot.txt \n",
    "\n",
    "usearch -id 0.5 -evalue 0.001 -maxhits 10 -top_hits_only \\\n",
    "                           -userfields query+target+tlo+thi+id+bits+evalue \\\n",
    "                           -db $UNIREF100_udb -usearch_global ${NAME}.prod.no_metadata.faa -threads 32 -userout ${NAME}.prod.uniref100.txt\n",
    "\n",
    "usearch -id 0.5 -evalue 0.001 -maxhits 10 -top_hits_only \\\n",
    "                           -userfields query+target+tlo+thi+id+bits+evalue \\\n",
    "                           -db $KEGG_udb -usearch_global ${NAME}.prod.no_metadata.faa -threads 32 -userout ${NAME}.prod.kegg100.txt\n",
    " \n",
    "\n",
    " srun hmmsearch --tblout ${NAME}.prod.pfam -E 1e-3 --cpu 36 ${PFAM_hmm} \\\n",
    "                  ${NAME}.prod.no_metadata.faa > /dev/null\n",
    "\n",
    "    srun hmmsearch --tblout ${NAME}.prod.tigrfam -E 1e-3 --cpu 36 ${TIGRFAM_hmm} \\\n",
    "                   ${NAME}.prod.no_metadata.faa > /dev/null\n",
    "\n",
    "    srun hmmsearch --domtblout ${NAME}.prod.dbcan -E 0.1 --cpu 36 ~/nobackup446/practice/dbcan/db/dbCAN.txt \\\n",
    "                   ${NAME}.prod.no_metadata.faa > /dev/null\n",
    "\n",
    "    hmmscan-parser.py ${NAME}.prod.dbcan \\\n",
    "           > ${NAME}.prod.dbcan_summary\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 genomic features (Metaxa-rRNA, aragorn-non-rRNA, crisprdisco-CRISPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metaxa\n",
    "for FILENAME in *metadata.faa;do export NAME=$(echo ${FILENAME} | sed -e 's/\\(.*\\).prod.no_metadata.faa/\\1/g');\\\n",
    "    metaxa2 --cpu 2 -g ssu -i ${NAME}.prod.no_metadata.fna -o $NAME.metaxa.ssu; metaxa2 --cpu 3 -g lsu \\\n",
    "    -i ${NAME}.prod.no_metadata.fna -o $NAME.metaxa.lsu;\n",
    "\n",
    "#aragorn\n",
    "    aragorn -m -t -gcstd -l -a -q -rn -fon -o ${NAME}.aragorn ${NAME}.prod.no_metadata.fna; done\n",
    "\n",
    "#crisprdisco\n",
    "source activate /nesi/project/uoa02469/Software/PipelineSetup/crisprdisco_env\n",
    "\n",
    "echo \",Path\" > disco_input.csv\n",
    "ls *fna >test.txt\n",
    "#edit and remove extension in test.txt and combine with disco_input.csv (format : 0, genome)\n",
    "\n",
    "disco disco_input.csv  --outdir  disco_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 combine all annotation (Annotation aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for FILENAME in *prod.faa;do export NAME=$(echo ${FILENAME} | sed -e 's/\\(.*\\).prod.faa/\\1/g');\\\n",
    "annotationAggregator.py --ident 30.0 --coverage 70.0 \\\n",
    "                        -u ${NAME}.prod.uniprot.txt -r ${NAME}.prod.uniref100.txt -k ${NAME}.prod.kegg.txt \\\n",
    "                        -p ${NAME}.prod.pfam -i ${NAME}.prod.tigrfam \\\n",
    "                         -t ${NAME}.aragorn \\\n",
    "                        ${NAME}.fa ${NAME}.prod.fna ${NAME}.prod.faa complete_annotation/${NAME}.annotation;\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
